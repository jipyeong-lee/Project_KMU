{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'><font color=\"#CC3D3D\"><p>\n",
    "# A Simple DNN Model Ensemble\n",
    "- Make different DNN models by changing only the random seed values\n",
    "- Ensemble the models using the power mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image, clear_output\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/train_selected_0614_2.pkl', 'rb') as f:  # cv.pkl이라는 파일을 바이너리 읽기(rb)모드로 열어서 f라 하고\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/test_selected_0614_2.pkl', 'rb') as f:  # cv.pkl이라는 파일을 바이너리 읽기(rb)모드로 열어서 f라 하고\n",
    "    data_te = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('../input/y_train.csv').age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21587, 424), (14380, 424), (21587,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data_te.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5931256831258100406\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1408047310\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 658988843175493956\n",
      "physical_device_desc: \"device: 0, name: GeForce MX250, pci bus id: 0000:3a:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set random seeds to make your results reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매번 모델링을 할 때마다 동일한 결과를 얻으려면 아래 코드를 실행해야 함.\n",
    "\n",
    "def reset_seeds(s1,s2,s3, reset_graph_with_backend=None):\n",
    "    if reset_graph_with_backend is not None:\n",
    "        K = reset_graph_with_backend\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        print(\"KERAS AND TENSORFLOW GRAPHS RESET\")  # optional\n",
    "\n",
    "    np.random.seed(s1)\n",
    "    random.seed(s2)\n",
    "    tf.compat.v1.set_random_seed(s3)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # for GPU\n",
    "#    print(\"RANDOM SEEDS RESET\")  # optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15110, 424), (6477, 424))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st round 2등팀의 훈련/평가/적용 데이터를 읽어온다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y_train, test_size=0.3, random_state=0)\n",
    "# 모델링에 사용되는 최종 학습 및 평가 데이터 확인\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split data into train & validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation\n",
    "i = int(round(X_train.shape[0] * 0.8,0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the hyper-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(hp):\n",
    "    inputs = keras.Input(shape=(X_train.shape[1],))\n",
    "    x = inputs\n",
    "    for i in range(hp.Int('num_layers', 2, 3)):\n",
    "        x = keras.layers.Dense(hp.Int('unit_'+ str(i), 16, 64, step=16), activation='swish')(x)\n",
    "        x = keras.layers.Dropout(hp.Float('dropout_'+str(i), 0, 0.5, step=0.25, default=0.5))(x)\n",
    "    outputs = keras.layers.Dense(1, activation='linear')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss='mse', \n",
    "                    optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), \n",
    "                    metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build multiple hyper-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 71.3012 - root_mean_squared_error: 8.4434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████                                                                | 1/5 [41:17<2:45:10, 2477.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 71.4206 - root_mean_squared_error: 8.4501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▏                                              | 2/5 [1:17:44<1:59:31, 2390.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 71.4693 - root_mean_squared_error: 8.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████▊                               | 3/5 [1:53:57<1:17:30, 2325.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 69.0632 - root_mean_squared_error: 8.3099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 4/5 [2:32:35<38:43, 2323.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "203/203 [==============================] - 0s 1ms/step - loss: 69.8941 - root_mean_squared_error: 8.3594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [3:14:38<00:00, 2335.70s/it]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "rmses = []\n",
    "preds = []\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    for i in tqdm(range(N)):\n",
    "        reset_seeds(i,i*10,i*100)\n",
    "        tuner = kt.Hyperband(model_fn,\n",
    "                         objective=kt.Objective('val_root_mean_squared_error', direction=\"min\"), \n",
    "                         max_epochs=50,\n",
    "                         hyperband_iterations=5,\n",
    "                         overwrite=True,\n",
    "                         directory='dnn_tuning')\n",
    "        tuner.search(X_train, y_train, validation_data=(X_valid, y_valid), \n",
    "                 callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)], verbose=0)\n",
    "        model = tuner.get_best_models(1)[0]\n",
    "        rmses.append(model.evaluate(X_test, y_test)[1])\n",
    "        preds.append(model.predict(data_te).flatten())         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Ensemble models & make submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Summary:\n",
      "3    8.360998\n",
      "4    8.419109\n",
      "0    8.503122\n",
      "2    8.505464\n",
      "1    8.524975\n",
      "dtype: float64\n",
      "mean=8.46273, std=0.070\n"
     ]
    }
   ],
   "source": [
    "print('\\nEvaluation Summary:')\n",
    "rmses = pd.Series(rmses)\n",
    "print(rmses.sort_values())\n",
    "print('mean={:.5f}, std={:.3f}'.format(rmses.mean(), rmses.std()))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power mean ensemble\n",
    "THRESHOLD = 8.75  # 이 값보다 성능이 나쁜 prediction은 버림.\n",
    "p = 1\n",
    "pred = 0\n",
    "n = 0\n",
    "for i in range(N):\n",
    "    if rmses.iloc[i] < THRESHOLD:\n",
    "        pred = pred + preds[i]**p \n",
    "        n += 1\n",
    "pred = pred / n    \n",
    "pred = pred**(1/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dnn_submission_06150309.csv' is ready to submit.\n"
     ]
    }
   ],
   "source": [
    "# Make submissions: 앙상블 (전)8.59847 => (후)8.54436\n",
    "t = pd.Timestamp.now()\n",
    "fname = f\"dnn_submission_{t.month:02}{t.day:02}{t.hour:02}{t.minute:02}.csv\"\n",
    "sub = pd.read_csv(os.path.abspath(\"../input\")+'/submission_test.csv')\n",
    "sub['age'] = pred\n",
    "sub.to_csv(fname, index=False)\n",
    "print(f\"'{fname}' is ready to submit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#CC3D3D\"><p>\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
